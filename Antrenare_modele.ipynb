{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7540319,"sourceType":"datasetVersion","datasetId":4390793}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Readability Prediction","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-12T16:19:20.722914Z","iopub.execute_input":"2024-05-12T16:19:20.723498Z","iopub.status.idle":"2024-05-12T16:19:21.843320Z","shell.execute_reply.started":"2024-05-12T16:19:20.723469Z","shell.execute_reply":"2024-05-12T16:19:21.842465Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/code-snippets-insights-and-readability/data_cpp.csv\n/kaggle/input/code-snippets-insights-and-readability/data_python.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.pipeline import make_pipeline","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:19:21.845269Z","iopub.execute_input":"2024-05-12T16:19:21.845672Z","iopub.status.idle":"2024-05-12T16:19:23.327504Z","shell.execute_reply.started":"2024-05-12T16:19:21.845644Z","shell.execute_reply":"2024-05-12T16:19:23.326627Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df1 = pd.read_csv(\"/kaggle/input/code-snippets-insights-and-readability/data_python.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:19:23.328840Z","iopub.execute_input":"2024-05-12T16:19:23.329195Z","iopub.status.idle":"2024-05-12T16:19:23.408284Z","shell.execute_reply.started":"2024-05-12T16:19:23.329154Z","shell.execute_reply":"2024-05-12T16:19:23.406897Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df1[\"python_solutions\"] = [x[20:] for x in df1[\"python_solutions\"]]","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:19:29.235577Z","iopub.execute_input":"2024-05-12T16:19:29.236201Z","iopub.status.idle":"2024-05-12T16:19:29.247559Z","shell.execute_reply.started":"2024-05-12T16:19:29.236170Z","shell.execute_reply":"2024-05-12T16:19:29.246666Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"X = df1[['num_of_lines', 'code_length', 'comments', 'cyclomatic_complexity', 'indents', 'loop_count', 'identifiers']]\ny = df1['readability']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X.values, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:19:29.529236Z","iopub.execute_input":"2024-05-12T16:19:29.530037Z","iopub.status.idle":"2024-05-12T16:19:29.548070Z","shell.execute_reply.started":"2024-05-12T16:19:29.529995Z","shell.execute_reply":"2024-05-12T16:19:29.547116Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import sklearn\n\nprint(\"Scikit-learn version:\", sklearn.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:19:30.719856Z","iopub.execute_input":"2024-05-12T16:19:30.720489Z","iopub.status.idle":"2024-05-12T16:19:30.725481Z","shell.execute_reply.started":"2024-05-12T16:19:30.720457Z","shell.execute_reply":"2024-05-12T16:19:30.724537Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Scikit-learn version: 1.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"model_read = make_pipeline(RandomForestRegressor(n_estimators=50, random_state=0))\nmodel_read.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:19:31.415803Z","iopub.execute_input":"2024-05-12T16:19:31.416466Z","iopub.status.idle":"2024-05-12T16:19:31.688655Z","shell.execute_reply.started":"2024-05-12T16:19:31.416438Z","shell.execute_reply":"2024-05-12T16:19:31.687804Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Pipeline(steps=[('randomforestregressor',\n                 RandomForestRegressor(n_estimators=50, random_state=0))])","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;randomforestregressor&#x27;,\n                 RandomForestRegressor(n_estimators=50, random_state=0))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;randomforestregressor&#x27;,\n                 RandomForestRegressor(n_estimators=50, random_state=0))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(n_estimators=50, random_state=0)</pre></div></div></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred = model_read.predict(X_test)\nmae = mean_absolute_error(y_test, y_pred)\nprint(f'Mean Absolute Error: {mae}')","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:19:40.679173Z","iopub.execute_input":"2024-05-12T16:19:40.680074Z","iopub.status.idle":"2024-05-12T16:19:40.694119Z","shell.execute_reply.started":"2024-05-12T16:19:40.680033Z","shell.execute_reply":"2024-05-12T16:19:40.693057Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Mean Absolute Error: 0.29876820914776364\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom joblib import dump\n\n# Creating and training the model\nmodel_read = make_pipeline(RandomForestRegressor(n_estimators=50, random_state=0))\nmodel_read.fit(X_train, y_train)\n\n# Saving the model to a file\ndump(model_read, 'random_forest_model.joblib')","metadata":{"execution":{"iopub.status.busy":"2024-05-12T16:19:50.308150Z","iopub.execute_input":"2024-05-12T16:19:50.308489Z","iopub.status.idle":"2024-05-12T16:19:50.604160Z","shell.execute_reply.started":"2024-05-12T16:19:50.308463Z","shell.execute_reply":"2024-05-12T16:19:50.602917Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['random_forest_model.joblib']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Task Complexity Regression","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import RobertaTokenizer, TFRobertaModel","metadata":{"execution":{"iopub.status.busy":"2024-05-12T15:24:38.271283Z","iopub.execute_input":"2024-05-12T15:24:38.271936Z","iopub.status.idle":"2024-05-12T15:24:53.250955Z","shell.execute_reply.started":"2024-05-12T15:24:38.271908Z","shell.execute_reply":"2024-05-12T15:24:53.250121Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-05-12 15:24:39.812731: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-12 15:24:39.812829: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-12 15:24:39.927912: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"df2 = pd.read_csv(\"/kaggle/input/code-snippets-insights-and-readability/data_python.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-05-12T15:24:53.252437Z","iopub.execute_input":"2024-05-12T15:24:53.252952Z","iopub.status.idle":"2024-05-12T15:24:53.304151Z","shell.execute_reply.started":"2024-05-12T15:24:53.252926Z","shell.execute_reply":"2024-05-12T15:24:53.303217Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df2[\"python_solutions\"] = [x[20:] for x in df2[\"python_solutions\"]]","metadata":{"execution":{"iopub.status.busy":"2024-05-12T15:24:53.305493Z","iopub.execute_input":"2024-05-12T15:24:53.306200Z","iopub.status.idle":"2024-05-12T15:24:53.316069Z","shell.execute_reply.started":"2024-05-12T15:24:53.306167Z","shell.execute_reply":"2024-05-12T15:24:53.315099Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"difficulty_dict = {\n    \"Easy\": 1,\n    \"Medium\": 2,\n    \"Hard\": 3\n}\n\ndf2[\"difficulty\"] = [difficulty_dict[x] for x in df2[\"difficulty\"]]","metadata":{"execution":{"iopub.status.busy":"2024-05-12T15:24:53.318683Z","iopub.execute_input":"2024-05-12T15:24:53.319540Z","iopub.status.idle":"2024-05-12T15:24:53.325584Z","shell.execute_reply.started":"2024-05-12T15:24:53.319515Z","shell.execute_reply":"2024-05-12T15:24:53.324647Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\nmodel = TFRobertaModel.from_pretrained(\"microsoft/codebert-base\")","metadata":{"execution":{"iopub.status.busy":"2024-05-12T15:24:53.326806Z","iopub.execute_input":"2024-05-12T15:24:53.327143Z","iopub.status.idle":"2024-05-12T15:25:06.944205Z","shell.execute_reply.started":"2024-05-12T15:24:53.327112Z","shell.execute_reply":"2024-05-12T15:25:06.943269Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"019d3ed02eb14064bb17f9790a6a3b06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbefbc83b16f493280b15525cc796fe2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b939bde4274473f8fbb22ddab83e885"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa60e8bfbbbd470e9b3993c1b43e84ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2eb1da735a694ed8b7bc389cf0b7b5cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tf_model.h5:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac534f05f7ff4085a32820d652f279a1"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFRobertaModel.\n\nAll the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_model():\n    input_ids = tf.keras.layers.Input(shape=(128,), dtype=tf.int32)  # Assuming fixed input sequence length of 128\n    roberta_model = TFRobertaModel.from_pretrained(\"roberta-base\")\n    embedding_layer = roberta_model(input_ids)[0]  # Extract embeddings from RoBERTa model\n    pooled_output = tf.keras.layers.GlobalAveragePooling1D()(embedding_layer)\n    output = tf.keras.layers.Dense(1)(pooled_output)\n    model_output = tf.keras.Model(inputs=input_ids, outputs=output)\n    return model_output","metadata":{"execution":{"iopub.status.busy":"2024-05-12T15:25:06.945260Z","iopub.execute_input":"2024-05-12T15:25:06.945543Z","iopub.status.idle":"2024-05-12T15:25:06.951546Z","shell.execute_reply.started":"2024-05-12T15:25:06.945519Z","shell.execute_reply":"2024-05-12T15:25:06.950592Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"X = df2['python_solutions']\ny = df2['difficulty']","metadata":{"execution":{"iopub.status.busy":"2024-05-12T15:25:06.952742Z","iopub.execute_input":"2024-05-12T15:25:06.953082Z","iopub.status.idle":"2024-05-12T15:25:06.963151Z","shell.execute_reply.started":"2024-05-12T15:25:06.953053Z","shell.execute_reply":"2024-05-12T15:25:06.962278Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import TFAutoModel, AutoTokenizer\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\n\n# Load the CodeBERT model and tokenizer\nmodel_name = \"microsoft/codebert-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ncodebert_model = TFAutoModel.from_pretrained(model_name)\n\n# Sample data (array of Python code strings and corresponding labels)\ncode_samples = X\nlabels = y\n\n# Tokenize input code samples\ninput_ids = []\nattention_masks = []\nfor code in code_samples:\n    encoded = tokenizer(code, padding='max_length', truncation=True, max_length=128, return_tensors='tf')\n    input_ids.append(encoded['input_ids'])\n    attention_masks.append(encoded['attention_mask'])\n\n# Convert lists to arrays\ninput_ids = np.array([np.squeeze(input_id) for input_id in input_ids])\nattention_masks = np.array([np.squeeze(mask) for mask in attention_masks])\nlabels = np.array(labels)\n\n# Split data into train and validation sets\ntrain_input_ids, val_input_ids, train_attention_masks, val_attention_masks, train_labels, val_labels = train_test_split(\n    input_ids, attention_masks, labels, test_size=0.2, random_state=42)\n\n# Define the neural network architecture\ninput_ids_input = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"input_ids\")\nattention_masks_input = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"attention_masks\")\n\ncodebert_output = codebert_model(input_ids_input, attention_mask=attention_masks_input)[0]\npooled_output = tf.keras.layers.GlobalAveragePooling1D()(codebert_output)\noutput = tf.keras.layers.Dense(1, activation='linear')(pooled_output)  # Linear activation for regression\n\n# Define the model\nmodel = tf.keras.Model(inputs=[input_ids_input, attention_masks_input], outputs=output)\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'mse'])\n\n# Train the model\nmodel.fit([train_input_ids, train_attention_masks], train_labels, epochs=1, batch_size=32, validation_data=([val_input_ids, val_attention_masks], val_labels))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-12T15:25:06.964193Z","iopub.execute_input":"2024-05-12T15:25:06.964490Z","iopub.status.idle":"2024-05-12T15:27:29.141216Z","shell.execute_reply.started":"2024-05-12T15:25:06.964460Z","shell.execute_reply":"2024-05-12T15:27:29.140267Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"All model checkpoint layers were used when initializing TFRobertaModel.\n\nAll the layers of TFRobertaModel were initialized from the model checkpoint at microsoft/codebert-base.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1715527588.232975     115 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"42/42 [==============================] - 117s 1s/step - loss: 3.1707 - mae: 0.9495 - mse: 3.1707 - val_loss: 0.5612 - val_mae: 0.6291 - val_mse: 0.5612\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<tf_keras.src.callbacks.History at 0x7ef41ac8c8e0>"},"metadata":{}}]},{"cell_type":"code","source":"# Save the model in HDF5 format\nmodel.save(\"codebert_model.h5\")\n\ntokenizer.save_pretrained('codebert_tokenizer')","metadata":{"execution":{"iopub.status.busy":"2024-04-23T18:04:18.423336Z","iopub.execute_input":"2024-04-23T18:04:18.423954Z","iopub.status.idle":"2024-04-23T18:06:08.982504Z","shell.execute_reply.started":"2024-04-23T18:04:18.423920Z","shell.execute_reply":"2024-04-23T18:06:08.981501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}